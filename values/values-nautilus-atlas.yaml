triton:
  name: triton-atlas
  image: milescb/traccc-aas:v1.1
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                  - NVIDIA-A10
                  # - NVIDIA-A40
                  # - NVIDIA-A100-SXM4-80GB
                  # - NVIDIA-L40
                  # - NVIDIA-A100-80GB-PCIe
                  # - NVIDIA-A100-80GB-PCIe-MIG-1g.10gb
                  # - NVIDIA-L4
                  # - NVIDIA-A100-PCIE-40GB
                  # - NVIDIA-GH200-480GB
  command: ["/bin/sh", "-c"]
  args:
    - |
      /opt/tritonserver/bin/tritonserver \
      --model-repository=/traccc-aaS/traccc-aaS/backend/models \
      --log-verbose=1 \
      --exit-on-error=true
  resources:
    limits: { nvidia.com/gpu: 1, cpu: 2, memory: 16G }
    requests: { nvidia.com/gpu: 1, cpu: 2, memory: 16G }
  replicas: 4
  modelRepository:
    enabled: true
    storageType: cvmfs-pvc
    mountPath: /cvmfs
envoy:
  enabled: true
  loadBalancerPolicy: "ROUND_ROBIN"
prometheus:
  url: "prometheus.nrp-nautilus.io"
  port: 443
  scheme: https
  serverLoadThreshold: 100
autoscaler:
  enabled: False
  minReplicas: 0
  maxReplicas: 1
ingress:
  enabled: true
  hostName: atlas.nrp-nautilus.io
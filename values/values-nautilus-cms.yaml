nameOverride: supersonic-cms

triton:
  # image: fastml/triton-torchgeo:21.02-py3-geometric # run2
  image: fastml/triton-torchgeo:22.07-py3-geometric # run3
  command: ["/bin/sh", "-c"]
  args: 
    - |
      /opt/tritonserver/bin/tritonserver \
      --model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoBTag/Combined/data/models/ \
      --model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoEgamma/EgammaPhotonProducers/data/models/ \
      --model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoTauTag/TrainingFiles/data/DeepTauIdSONIC/ \
      --model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoMET/METPUSubtraction/data/models/ \
      --allow-gpu-metrics=true \
      --log-verbose=1 \
      --strict-model-config=false \
      --exit-timeout-secs=60 \
      --backend-config=onnxruntime,enable-global-threadpool=1
  resources:
    limits: { cpu: 2, memory: 16G}
    requests: { cpu: 2, memory: 16G}
  service:
    labels:
      scrape_metrics: "true"
    annotations:
      metallb.universe.tf/address-pool: geddes-private-pool
    ports:
      - { name: http, port: 8000, targetPort: 8000, protocol: TCP }
      - { name: grpc, port: 8001, targetPort: 8001, protocol: TCP }
      - { name: metrics, port: 8002, targetPort: 8002, protocol: TCP }
  modelRepository:
    storageType: cvmfs-pvc
    mountPath: /cvmfs
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                  - NVIDIA-A10
                  - NVIDIA-A40
                  # - NVIDIA-A100-SXM4-80GB
                  - NVIDIA-L40
                  # - NVIDIA-A100-80GB-PCIe
                  # - NVIDIA-A100-80GB-PCIe-MIG-1g.10gb
                  - NVIDIA-L4
                  # - NVIDIA-A100-PCIE-40GB
                  # - NVIDIA-GH200-480GB
envoy:
  enabled: true
  image: envoyproxy/envoy:v1.30-latest
  args: ["--config-path", "/etc/envoy/envoy.yaml", "--log-level", "info", "--log-path", "/dev/stdout"]
  resources:
    requests: { cpu: 1, memory: 2Gi }
    limits: { cpu: 2, memory: 4Gi }
  service:
    type: ClusterIP
    labels:
      envoy: "true"
    ports:
      - { name: grpc, port: 8001, targetPort: 8001 }
      - { name: admin, port: 9901, targetPort: 9901 }
  configs:
    luaConfig: "cfg/envoy-filter.lua"
  loadBalancerPolicy: LEAST_REQUEST
prometheus:
  url: "prometheus.nrp-nautilus.io"
  port: 443
  scheme: https
  serverAvailabilityMetric: |-
    sum(
      sum by (pod) (
        rate(nv_inference_queue_duration_us{pod=~"supersonic.*"}[5m:1m])
      )
      /
      sum by (pod) (
        (rate(nv_inference_exec_count{pod=~"supersonic.*"}[5m:1m]) + 0.00001) * 1000
      )
    )
  serverAvailabilityThreshold: 10
autoscaler:
  enabled: True
  minReplicas: 1
  maxReplicas: 5
ingress:
  enabled: true
  hostName: sonic-cms.nrp-nautilus.io

# For Run3:
# Triton image:  fastml/triton-torchgeo:22.07-py3-geometric
# Models: /depot/cms/sonic/yao317/models/sonic-models/models_2023

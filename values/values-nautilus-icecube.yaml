serverLoadThreshold: 100

triton: 
  image: nvcr.io/nvidia/tritonserver:24.06-py3
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          # - key: topology.kubernetes.io/region
          #   operator: In
          #   values:
          #   - us-west
          # - key: nvidia.com/gpu.memory
          #   operator: Gt
          #   values:
          #   - "15000"
          - key: nvidia.com/gpu.product
            operator: In
            values:
            # - NVIDIA-A10
            # - NVIDIA-A40
            # - NVIDIA-A100-SXM4-80GB
            - NVIDIA-L40
            # - NVIDIA-A100-80GB-PCIe
            # - NVIDIA-A100-80GB-PCIe-MIG-1g.10gb
            - NVIDIA-L4
            # - NVIDIA-A100-PCIE-40GB
            # - NVIDIA-GH200-480GB
  args: [tritonserver, 
    --model-repository=/models/icecube.opensciencegrid.org/users/briedel/ml/models, 
    --log-error=true,
    --exit-on-error=true]
  resources:
    limits: { nvidia.com/gpu: 1, cpu: 2, memory: 24Gi }
    requests: { nvidia.com/gpu: 1, cpu: 2, memory: 20Gi }
  modelRepository:
    enabled: true
    storageType: cvmfs-pvc
    mountPath: /models

envoy:
  enabled: true
  auth:
    enabled: true
    jwt_issuer: https://keycloak.icecube.wisc.edu/auth/realms/IceCube
    jwt_remote_jwks_uri: https://keycloak.icecube.wisc.edu/auth/realms/IceCube/protocol/openid-connect/certs
    audiences: [icecube]
    url: keycloak.icecube.wisc.edu
    port: 443
  ingress:
    enabled: true
    hostName: icesonic.nrp-nautilus.io
    ingressClassName: haproxy
    annotations:
      haproxy-ingress.github.io/cors-enable: "true"
      haproxy-ingress.github.io/backend-protocol: "h2"
      haproxy-ingress.github.io/proxy-body-size: "512m"
      haproxy-ingress.github.io/timeout-client: "5m"
      haproxy-ingress.github.io/timeout-server: "5m"
      haproxy-ingress.github.io/timeout-connect: "5m"
      haproxy-ingress.github.io/timeout-http-request: "5m"
      haproxy-ingress.github.io/timeout-queue: "1m"
      haproxy-ingress.github.io/health-check-interval: "30s"
      haproxy-ingress.github.io/health-check-rise-count: "1"

autoscaler:
  enabled: false
  minReplicaCount: 0
  maxReplicaCount: 1

prometheus:
  external:
    enabled: true
    url: "prometheus.nrp-nautilus.io"
    port: 443
    scheme: https

grafana:
  enabled: true
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: prometheus
          type: prometheus
          access: proxy
          isDefault: true
          url: https://prometheus.nrp-nautilus.io
          jsonData:
            timeInterval: "5s"
            tlsSkipVerify: true
  ingress:
    enabled: true
    hosts:
      - grafana-icecube.nrp-nautilus.io
    tls:
      - hosts:
          - grafana-icecube.nrp-nautilus.io
    ingressClassName: haproxy
    annotations:
      haproxy-ingress.github.io/cors-enable: "true"
      haproxy-ingress.github.io/backend-protocol: "h2"
      haproxy-ingress.github.io/proxy-body-size: "512m"
  grafana.ini:
    server:
      root_url: https://grafana-icecube.nrp-nautilus.io

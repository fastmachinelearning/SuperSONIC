triton:
  # image: fastml/triton-torchgeo:21.02-py3-geometric # run2
  image: fastml/triton-torchgeo:22.07-py3-geometric # run3
  command: ["/bin/sh", "-c"]
  args: 
    - |
      /opt/tritonserver/bin/tritonserver \
      --model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoBTag/Combined/data/models/ \
      --model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoEgamma/EgammaPhotonProducers/data/models/ \
      --model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoTauTag/TrainingFiles/data/DeepTauIdSONIC/ \
      --model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoMET/METPUSubtraction/data/models/ \
      --allow-gpu-metrics=true \
      --log-verbose=1 \
      --strict-model-config=false \
      --exit-timeout-secs=60 \
      --backend-config=onnxruntime,enable-global-threadpool=1
  resources:
    limits: { cpu: 2, memory: 16G}
    requests: { cpu: 2, memory: 16G}
  modelRepository:
    enabled: true
    storageType: cvmfs-pvc
    mountPath: /cvmfs
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                  - NVIDIA-A10
                  - NVIDIA-A100-SXM4-80GB
envoy:
  enabled: true
# prometheus:
#   url: "prometheus.nrp-nautilus.io"
#   port: 443
#   scheme: https
#   serverLoadThreshold: 10
autoscaler:
  enabled: False
  minReplicas: 1
  maxReplicas: 5
ingress:
  enabled: true
  hostName: sonic-cms.anvilcloud.rcac.purdue.edu

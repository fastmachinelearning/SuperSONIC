

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Configuration Guide &mdash; SuperSONIC  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=cba22156" />

  
    <link rel="shortcut icon" href="_static/SuperSONIC_small.svg"/>
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9a2dae69"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Configuration Reference" href="configuration-reference.html" />
    <link rel="prev" title="Getting Started" href="getting-started.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="index.html">
            
              <img src="_static/SuperSONIC_light.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting Started</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Configuration Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#select-a-triton-inference-server-version">1. Select a Triton Inference Server Version</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configure-triton-model-repository">2. Configure Triton model repository</a></li>
<li class="toctree-l2"><a class="reference internal" href="#select-resources-for-triton-pods">1. Select Resources for Triton Pods</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configure-envoy-proxy">4. Configure Envoy Proxy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#optional-configure-rate-limiting-in-envoy-proxy">5. (Optional) Configure Rate Limiting in Envoy Proxy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#optional-configure-authentication-in-envoy-proxy">6. (Optional) Configure Authentication in Envoy Proxy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#deploy-a-prometheus-server-or-connect-to-an-existing-one">7. Deploy a Prometheus Server or Connect to an Existing One</a></li>
<li class="toctree-l2"><a class="reference internal" href="#optional-configure-metrics-for-scaling-and-rate-limiting">8. (Optional) Configure Metrics for Scaling and Rate Limiting</a></li>
<li class="toctree-l2"><a class="reference internal" href="#optional-deploy-grafana-dashboard">9. (Optional) Deploy Grafana Dashboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="#enable-keda-autoscaler">10. Enable KEDA Autoscaler</a></li>
<li class="toctree-l2"><a class="reference internal" href="#optional-configure-metrics-collector-for-running-perf-analyzer">11. (Optional) Configure Metrics Collector for Running <code class="docutils literal notranslate"><span class="pre">perf_analyzer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#optional-configure-advanced-monitoring">12. (Optional) Configure Advanced Monitoring</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="configuration-reference.html">Configuration Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced-monitoring.html">Advanced Monitoring</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SuperSONIC</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Configuration Guide</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/fastmachinelearning/SuperSONIC/blob/main/docs/configuration-guide.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="configuration-guide">
<h1>Configuration Guide<a class="headerlink" href="#configuration-guide" title="Link to this heading"></a></h1>
<p>The following guide will help you configure <code class="docutils literal notranslate"><span class="pre">values.yaml</span></code> file for a SuperSONIC deployment.
The full list of parameters can be found in the <a class="reference external" href="configuration-reference">Configuration Reference</a>.</p>
<p>You can find example values files in the <a class="reference external" href="https://github.com/fastmachinelearning/SuperSONIC/tree/main/values">SuperSONIC GitHub repository</a>.</p>
<section id="select-a-triton-inference-server-version">
<h2>1. Select a Triton Inference Server Version<a class="headerlink" href="#select-a-triton-inference-server-version" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>Official versions can be found at <a class="reference external" href="https://ngc.nvidia.com/catalog/containers/nvidia:tritonserver">NVIDIA NGC</a>.</p></li>
<li><p>You can also use custom-built Triton images.</p></li>
<li><p>Refer to the <a class="reference external" href="https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html">Nvidia Frameworks Support Matrix</a>
for compatibility information (CUDA versions, NVIDIA drivers, etc.).</p></li>
</ul>
<p>Triton version must be specified in the <code class="docutils literal notranslate"><span class="pre">triton.image</span></code> parameter in the values file.</p>
</section>
<section id="configure-triton-model-repository">
<h2>2. Configure Triton model repository<a class="headerlink" href="#configure-triton-model-repository" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>To learn about the structure of model repositories, refer to the
<a class="reference external" href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_repository.html">NVIDIA Model Repository Guide</a>.</p></li>
<li><p>Model repositories are specified in the <code class="docutils literal notranslate"><span class="pre">triton.args</span></code> parameter in the values file.
The parameter contains the full command that launches a Triton server; you can specify
one or multiple model repositories via the <code class="docutils literal notranslate"><span class="pre">--model-repository</span></code> flag.</p></li>
<li><p>For example, the following command loads multiple CMS models hosted at CVMFS:</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">args</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">   </span><span class="no">/opt/tritonserver/bin/tritonserver \</span>
<span class="w">   </span><span class="no">--model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoBTag/Combined/data/models/ \</span>
<span class="w">   </span><span class="no">--model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoTauTag/TrainingFiles/data/DeepTauIdSONIC/ \</span>
<span class="w">   </span><span class="no">--model-repository=/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_1_0_pre7/external/el9_amd64_gcc12/data/RecoMET/METPUSubtraction/data/models/ \</span>
<span class="w">   </span><span class="no">--allow-gpu-metrics=true \</span>
<span class="w">   </span><span class="no">--log-verbose=0 \</span>
<span class="w">   </span><span class="no">--strict-model-config=false \</span>
<span class="w">   </span><span class="no">--exit-timeout-secs=60</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Make sure that the model repository paths exist. You can load models from a volume mounted to the Triton container.
The following options for model repository mounting are provided via <code class="docutils literal notranslate"><span class="pre">triton.modelRepository</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">values.yaml</span></code>:</p></li>
</ul>
<details>
<summary>Model repository options</summary><div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># -- Model repository configuration</span>
<span class="nt">modelRepository</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Set to `true` to enable model repository mounting</span>
<span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="w">  </span><span class="c1"># -- Model repository mount path (e.g /cvmfs/)</span>
<span class="w">  </span><span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&quot;</span>

<span class="w">  </span><span class="c1">## Model repository options:</span>

<span class="w">  </span><span class="c1">## Option 1: mount an arbitrary PersistentVolumeClaim</span>
<span class="w">  </span><span class="nt">storageType</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;pvc&quot;</span>
<span class="w">  </span><span class="nt">pvc</span><span class="p">:</span>
<span class="w">    </span><span class="nt">claimName</span><span class="p">:</span>

<span class="w">  </span><span class="c1">## -- OR --</span>
<span class="w">  </span><span class="c1">## Option 2: mount CVMFS as PersistentVolumeClaim (CVMFS StorageClass must be installed at the cluster)</span>
<span class="w">  </span><span class="nt">storageType</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;cvmfs-pvc&quot;</span>

<span class="w">  </span><span class="c1">## -- OR --</span>
<span class="w">  </span><span class="c1">## Option 3: mount CVMFS via hostPath (CVMFS must be already mounted on the nodes)</span>
<span class="w">  </span><span class="nt">storageType</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;cvmfs&quot;</span>

<span class="w">  </span><span class="c1">## -- OR --</span>
<span class="w">  </span><span class="c1">## Option 4: mount an NFS storage volume</span>
<span class="w">  </span><span class="nt">storageType</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;nfs&quot;</span>
<span class="w">  </span><span class="nt">nfs</span><span class="p">:</span>
<span class="w">    </span><span class="nt">server</span><span class="p">:</span>
<span class="w">    </span><span class="nt">path</span><span class="p">:</span>
</pre></div>
</div>
</details><br><br></section>
<section id="select-resources-for-triton-pods">
<h2>1. Select Resources for Triton Pods<a class="headerlink" href="#select-resources-for-triton-pods" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>You can configure CPU, memory, and GPU resources for Triton pods via the <code class="docutils literal notranslate"><span class="pre">triton.resources</span></code> parameter in the values file:</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">resources</span><span class="p">:</span>
<span class="w">  </span><span class="nt">limits</span><span class="p">:</span>
<span class="w">    </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16G</span>
<span class="w">  </span><span class="nt">requests</span><span class="p">:</span>
<span class="w">    </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16G</span>
</pre></div>
</div>
<ul class="simple">
<li><p>In addition, you can use <code class="docutils literal notranslate"><span class="pre">triton.nodeSelector</span></code>, <code class="docutils literal notranslate"><span class="pre">triton.tolerations</span></code>,
<code class="docutils literal notranslate"><span class="pre">triton.annotations</span></code>, and <code class="docutils literal notranslate"><span class="pre">triton.affinity</span></code> to steer Triton pods to specific nodes.
This is particularly useful for co-locating Triton pods with Envoy proxy to reduce latency.</p></li>
</ul>
</section>
<section id="configure-envoy-proxy">
<h2>4. Configure Envoy Proxy<a class="headerlink" href="#configure-envoy-proxy" title="Link to this heading"></a></h2>
<p>By default, Envoy proxy is enabled and configured to provide per-request
load balancing between Triton inference servers.</p>
<p>Once the SuperSONIC chart is installed, you need an address by which clients
can connect to the Envoy proxy and send inference requests.</p>
<p>There are two options:</p>
<ul>
<li><p><strong>Ingress</strong> (recommended): Use an Ingress to expose the Envoy proxy to the outside world.
You can configure the Ingress resource via the <code class="docutils literal notranslate"><span class="pre">envoy.ingress</span></code> parameters in the values file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">envoy</span><span class="p">:</span>
<span class="w">  </span><span class="nt">ingress</span><span class="p">:</span>
<span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">hostName</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;ingress_url&gt;&quot;</span>
<span class="w">    </span><span class="nt">ingressClassName</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;ingress_class&gt;&quot;</span>
<span class="w">    </span><span class="nt">annotations</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{}</span>
</pre></div>
</div>
<p>In this case, the client connections should be established to  <code class="docutils literal notranslate"><span class="pre">&lt;ingress_url&gt;:443</span></code> and use SSL.</p>
<p>For information on how to configure Ingress for your cluster, please refer to cluster documentation or contact cluster administrators.</p>
</li>
<li><p><strong>LoadBalancer Service</strong>: This option allows to expose the Envoy proxy without using Ingress, but it may
not be allowed at some Kubernetes clusters. To enable this, set the following parameters in the values file:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">envoy.service.type:</span> <span class="pre">LoadBalancer</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">envoy.ingress.enabled:</span> <span class="pre">false</span></code></p></li>
</ul>
<p>The LoadBalancer service can then be mapped to an external URL, depending on the settings of a given cluster.
Please contact cluster administrators for more information.</p>
<p>In this case, the client connections should be established to  <code class="docutils literal notranslate"><span class="pre">&lt;load_balancer_url&gt;:8001</span></code> and NOT use SSL.</p>
</li>
</ul>
<p>Some Envoy Proxy parameters, such as load balancing policy, rate limiting, and authentication,
can be cofigured directly in the <code class="docutils literal notranslate"><span class="pre">values.yaml</span></code> file as described in sections below.</p>
<p>Alternatively, you can provide an external Envoy configuration file to override the
default configuration completely (the configuration file must be supplied as a ConfigMap):</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">envoy</span><span class="p">:</span>
<span class="w">  </span><span class="nt">external_config</span><span class="p">:</span>
<span class="w">    </span><span class="nt">load_from_configmap</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">configmap_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">external-envoy-config</span>
<span class="w">    </span><span class="nt">configmap_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">envoy.yaml</span>
</pre></div>
</div>
</section>
<section id="optional-configure-rate-limiting-in-envoy-proxy">
<h2>5. (Optional) Configure Rate Limiting in Envoy Proxy<a class="headerlink" href="#optional-configure-rate-limiting-in-envoy-proxy" title="Link to this heading"></a></h2>
<p>There are two types of rate limiting available in Envoy Proxy: <em>listener-level</em>, and <em>prometheus-based</em>.</p>
<ul>
<li><p><strong>Listener-level rate limiting</strong> allows to explicitly limit the number of client connections established to the Envoy proxy endpoint.
It can be useful to prevent overloading the proxy with too many simultaneous client connections.</p>
<p>The listener-level rate limiting is implemented via “token bucket” algorithm.
Each new connection consumes a token from the bucket, and the bucket is refilled at a constant rate.</p>
<p>Example configuration in <code class="docutils literal notranslate"><span class="pre">values.yaml</span></code>:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">envoy</span><span class="p">:</span>
<span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">  </span><span class="nt">rate_limiter</span><span class="p">:</span>
<span class="w">    </span><span class="nt">listener_level</span><span class="p">:</span>
<span class="w">      </span><span class="c1"># -- Enable rate limiter</span>
<span class="w">      </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">      </span><span class="c1"># -- Maximum number of simultaneous connections to the Envoy Proxy.</span>
<span class="w">      </span><span class="nt">max_tokens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="w">      </span><span class="c1"># -- ``tokens_per_fill`` tokens are added to the &quot;bucket&quot; every ``fill_interval``, allowing new connections to be established.</span>
<span class="w">      </span><span class="nt">tokens_per_fill</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">      </span><span class="c1"># -- For example, adding a new token every 12 seconds allows 5 new connections every minute.</span>
<span class="w">      </span><span class="nt">fill_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12s</span>
</pre></div>
</div>
</li>
<li><p><strong>Prometheus-based rate limiting</strong> allows an additional layer of rate limiting based on a metric queried from a Prometheus server.
This can be useful to dynamically control server load and stop accepting new connections when GPUs are saturated.</p>
<p>This rate limiter can be enabled via the <code class="docutils literal notranslate"><span class="pre">envoy.rate_limiter.prometheus_based</span></code> parameter in the values file.</p>
<p>At the moment, this functionality is configured to only reject <code class="docutils literal notranslate"><span class="pre">RepositoryIndex</span></code> requests to Triton servers, and it ignores
any other requests in order not to slow down the inferences.</p>
<p>The metric and threshold for the Prometheus-based rate limiter are the same as those used for the autoscaler (see Prometheus Configuration).</p>
</li>
</ul>
</section>
<section id="optional-configure-authentication-in-envoy-proxy">
<h2>6. (Optional) Configure Authentication in Envoy Proxy<a class="headerlink" href="#optional-configure-authentication-in-envoy-proxy" title="Link to this heading"></a></h2>
<p>At the moment, the only supported authentication method is JWT. Example configuration for IceCube:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">envoy</span><span class="p">:</span>
<span class="w">  </span><span class="nt">auth</span><span class="p">:</span>
<span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">jwt_issuer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">https://keycloak.icecube.wisc.edu/auth/realms/IceCube</span>
<span class="w">    </span><span class="nt">jwt_remote_jwks_uri</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">https://keycloak.icecube.wisc.edu/auth/realms/IceCube/protocol/openid-connect/certs</span>
<span class="w">    </span><span class="nt">audiences</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">icecube</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">keycloak.icecube.wisc.edu</span>
<span class="w">    </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">443</span>
</pre></div>
</div>
</section>
<section id="deploy-a-prometheus-server-or-connect-to-an-existing-one">
<h2>7. Deploy a Prometheus Server or Connect to an Existing One<a class="headerlink" href="#deploy-a-prometheus-server-or-connect-to-an-existing-one" title="Link to this heading"></a></h2>
<p>Prometheus is needed to scrape metrics for monitoring, as well as for the rate limiter and autoscaler.</p>
<ul>
<li><p><strong>Option 1</strong> (recommended): Deploy a new Prometheus server.</p>
<p>This will allow to configure a shorter scraping interval, resulting in a more responsive
rate limiter and autoscaler. Prometheus server typically uses only a small amount of resources
and does not require special permissions for installation.</p>
<p>This option installs Prometheus as a subchart, the default values for it are set to reasonable values.
You can further customize the Prometheus installation by passing parameters from
official Prometheus <a class="reference external" href="https://github.com/prometheus-community/helm-charts/blob/main/charts/prometheus/values.yaml">values.yaml</a> file
under the <code class="docutils literal notranslate"><span class="pre">prometheus</span></code> section of the SuperSONIC values file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">prometheus</span><span class="p">:</span>
<span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">  </span><span class="nt">server</span><span class="p">:</span>
<span class="w">    </span><span class="nt">ingress</span><span class="p">:</span>
<span class="w">      </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">ingressClassName</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;ingress_class&gt;&quot;</span>
<span class="w">      </span><span class="nt">hosts</span><span class="p">:</span>
<span class="w">         </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;&lt;prometheus_url&gt;&quot;</span>
<span class="w">      </span><span class="nt">tls</span><span class="p">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">hosts</span><span class="p">:</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;&lt;prometheus_url&gt;&quot;</span>
</pre></div>
</div>
<p>The parameters you will most likely need to configure in your values file are related to
Ingress for web access to Prometheus UI.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This option requires permissions to list pods in the installation namespace.
Permission validation is performed automatically: if you don’t have the necessary permissions,
an error message will be printed when running <code class="docutils literal notranslate"><span class="pre">helm</span> <span class="pre">install</span></code> command.</p>
</div>
</li>
<li><p><strong>Option 2</strong>: Connect to an existing Prometheus server.</p>
<p>If you don’t have enough permissions to install a new Prometheus server,
you can connect to an existing one. If <code class="docutils literal notranslate"><span class="pre">prometheus.external.enabled</span></code> is set to <code class="docutils literal notranslate"><span class="pre">true</span></code>,
all  parameters in the <code class="docutils literal notranslate"><span class="pre">prometheus</span></code> section, except the ones under
<code class="docutils literal notranslate"><span class="pre">prometheus.external</span></code>, are ignored.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">prometheus</span><span class="p">:</span>
<span class="w">  </span><span class="nt">external</span><span class="p">:</span>
<span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="l l-Scalar l-Scalar-Plain">scheme</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;&lt;https</span><span class="nv"> </span><span class="s">or</span><span class="nv"> </span><span class="s">http&gt;&quot;</span>
<span class="w">      </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;prometheus_url&gt;&quot;</span>
<span class="w">      </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;prometheus_port&gt;</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="optional-configure-metrics-for-scaling-and-rate-limiting">
<h2>8. (Optional) Configure Metrics for Scaling and Rate Limiting<a class="headerlink" href="#optional-configure-metrics-for-scaling-and-rate-limiting" title="Link to this heading"></a></h2>
<p>Both the rate limiter and the autoscaler are currently configured to use the same Prometheus metric and threshold.
They are defined in the <code class="docutils literal notranslate"><span class="pre">serverLoadMetric</span></code> and <code class="docutils literal notranslate"><span class="pre">serverLoadThreshold</span></code> parameters at the root level of the values file.
The default metric is the inference queue time at the Triton servers, as defined in
<a class="reference external" href="https://github.com/fastmachinelearning/SuperSONIC/blob/main/helm/supersonic/templates/_scaling-metric.tpl">here</a>.</p>
<p>When the metric value exceeds the threshold, the following happens:</p>
<ul class="simple">
<li><p>Autoscaler scales up the number of Triton servers if possible.</p></li>
<li><p>Envoy proxy rejects new <code class="docutils literal notranslate"><span class="pre">RepositoryIndex</span></code> requests.</p></li>
</ul>
<p>The pre-configured Grafana dashboard contains a graph of this metric, entitled “Server Load Metric”.
The Prometheus query for the graph is automatically inferred from the value of <code class="docutils literal notranslate"><span class="pre">serverLoadMetric</span></code> parameter.
The graph also displays the threshold value defined in <code class="docutils literal notranslate"><span class="pre">serverLoadThreshold</span></code> parameter.</p>
</section>
<section id="optional-deploy-grafana-dashboard">
<h2>9. (Optional) Deploy Grafana Dashboard<a class="headerlink" href="#optional-deploy-grafana-dashboard" title="Link to this heading"></a></h2>
<p>Grafana is used to visualize metrics collected by Prometheus.
We provide a pre-configured Grafana dashboard which includes many useful metrics,
including latency breakdown, GPU utilization, and more.</p>
<p>If you have a Grafana instance already installed, you can deploy SuperSONIC dashboars
by copying one of the JSON files from the
<a class="reference external" href="https://github.com/fastmachinelearning/SuperSONIC/tree/main/helm/supersonic/dashboards">SuperSONIC repository</a>.</p>
<p>If you don’t have a Grafana instance already installed, you can deploy one as a subchart of SuperSONIC,
in which case the dashboard will be automatically deployed.</p>
<p>You can further customize the Grafana installation by passing parameters from
official Grafana <a class="reference external" href="https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml">values.yaml</a> file
under the <code class="docutils literal notranslate"><span class="pre">grafana</span></code> section of the SuperSONIC values file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">grafana</span><span class="p">:</span>
<span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">  </span><span class="nt">ingress</span><span class="p">:</span>
<span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">ingressClassName</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;ingress_class&gt;&quot;</span>
<span class="w">    </span><span class="nt">hosts</span><span class="p">:</span>
<span class="w">       </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;&lt;grafana_url&gt;&quot;</span>
<span class="w">    </span><span class="nt">tls</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">hosts</span><span class="p">:</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;&lt;grafana_url&gt;&quot;</span>
</pre></div>
</div>
<p>The values you will most likely need to configure in your values file are related to
Grafana Ingress for web access, and datasources to connect to Prometheus,</p>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/grafana.png"><img alt="SuperSONIC Grafana Dashboard" src="_images/grafana.png" style="height: 200px;" />
</a>
</figure>
</section>
<section id="enable-keda-autoscaler">
<h2>10. Enable KEDA Autoscaler<a class="headerlink" href="#enable-keda-autoscaler" title="Link to this heading"></a></h2>
<p>Autoscaling is implemented via <a class="reference external" href="https://keda.sh/">KEDA (Kubernetes Event-Driven Autoscaler)</a> and
can be enabled via the <code class="docutils literal notranslate"><span class="pre">keda.enabled</span></code> parameter in the values file.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Deploying KEDA autoscaler requires KEDA CustomResourceDefinitions to be installed in the cluster.
Please contact cluster administrators if this step of installation fails.</p>
</div>
<p>The parameters <code class="docutils literal notranslate"><span class="pre">keda.minReplicaCount</span></code> and <code class="docutils literal notranslate"><span class="pre">keda.maxReplicaCount</span></code> define the range in which
the number of Triton servers can scale.</p>
<p>Additional optional parameters can control how quickly the autoscaler reacts to changes in the Prometheus metric:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">keda</span><span class="p">:</span>
<span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="w">  </span><span class="nt">minReplicaCount</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">maxReplicaCount</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span>

<span class="w">  </span><span class="nt">scaleUp</span><span class="p">:</span>
<span class="w">    </span><span class="nt">stabilizationWindowSeconds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">120</span>
<span class="w">    </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">30</span>
<span class="w">    </span><span class="nt">stepsize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">scaleDown</span><span class="p">:</span>
<span class="w">    </span><span class="nt">stabilizationWindowSeconds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">120</span>
<span class="w">    </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">30</span>
<span class="w">    </span><span class="nt">stepsize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
</pre></div>
</div>
</section>
<section id="optional-configure-metrics-collector-for-running-perf-analyzer">
<h2>11. (Optional) Configure Metrics Collector for Running <code class="docutils literal notranslate"><span class="pre">perf_analyzer</span></code><a class="headerlink" href="#optional-configure-metrics-collector-for-running-perf-analyzer" title="Link to this heading"></a></h2>
<p>To collect Prometheus metrics when using <code class="docutils literal notranslate"><span class="pre">perf_analyzer</span></code> for testing,
a Metrics Collector can be deployed to format Prometheus metrics properly.
The Metrics Collector is installed as a subchart with most of the default
values pre-configured. To enable the Metrics Collector, set the
<code class="docutils literal notranslate"><span class="pre">metricsCollector.enabled</span></code> parameter to <code class="docutils literal notranslate"><span class="pre">true</span></code> in your values file
and configure ingress settings if needed as shown below:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">metricsCollector</span><span class="p">:</span>
<span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">  </span><span class="nt">ingress</span><span class="p">:</span>
<span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">hostName</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;metrics_collector_url&gt;&quot;</span>
<span class="w">    </span><span class="nt">ingressClassName</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;ingress_class&gt;&quot;</span>
<span class="w">    </span><span class="nt">annotations</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{}</span>
</pre></div>
</div>
<p>Running with <code class="docutils literal notranslate"><span class="pre">perf_analyzer</span></code> is then done with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>perf_analyzer<span class="w"> </span>-m<span class="w"> </span>&lt;model_name&gt;<span class="w"> </span>-u<span class="w"> </span>&lt;envoy_engress&gt;<span class="w"> </span>-i<span class="w"> </span>grpc<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--collect-metrics<span class="w"> </span>--metrics-url<span class="w"> </span>&lt;metrics_collector_url&gt;/metrics<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--verbose-csv<span class="w"> </span>-f<span class="w"> </span>&lt;out_csv_file_name&gt;.csv
</pre></div>
</div>
<p>If ingress is not desired, port-forward the metrics collector service and call
<code class="docutils literal notranslate"><span class="pre">--metrics-url</span> <span class="pre">localhost:8003/metrics</span></code> to access the metrics.</p>
</section>
<section id="optional-configure-advanced-monitoring">
<h2>12. (Optional) Configure Advanced Monitoring<a class="headerlink" href="#optional-configure-advanced-monitoring" title="Link to this heading"></a></h2>
<p>Refer to the <a class="reference external" href="advanced-monitoring">advanced monitoring guide</a>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="getting-started.html" class="btn btn-neutral float-left" title="Getting Started" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="configuration-reference.html" class="btn btn-neutral float-right" title="Configuration Reference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Fast Machine Learning Lab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
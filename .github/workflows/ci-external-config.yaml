name: ci [external-config]

on:
  push:
    branches:
      - "**"
  pull_request:
    branches:
      - "main"

jobs:
  deploy-at-github:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Kubernetes cluster with Kind
        uses: helm/kind-action@v1.6.0
        with:
          cluster_name: gh-k8s-cluster

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: v3.12.0

      - name: Create CMS namespace
        run: |
          kubectl create namespace cms

      - name: Install Prometheus Operator CRDs
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update
          kubectl create namespace monitoring
          helm install prometheus-operator prometheus-community/kube-prometheus-stack --namespace monitoring --set prometheusOperator.createCustomResource=false --set defaultRules.create=false --set alertmanager.enabled=false --set prometheus.enabled=false --set grafana.enabled=false

      - name: Install KEDA Autoscaler
        run: |
          helm repo add kedacore https://kedacore.github.io/charts
          helm repo update
          kubectl create namespace keda
          helm install keda kedacore/keda --namespace keda

      - name: Mount CVMFS
        run: |
          kubectl create namespace cvmfs-csi
          helm install -n cvmfs-csi cvmfs-csi oci://registry.cern.ch/kubernetes/charts/cvmfs-csi --values cvmfs/values-cvmfs-csi.yaml
          kubectl apply -f cvmfs/cvmfs-storageclass.yaml -n cvmfs-csi

      - name: Create external Envoy ConfigMap
        run: |
          kubectl apply -f tests/envoy-config-test.yaml -n cms

      - name: Deploy Helm chart with external Envoy config
        run: |
          helm repo add grafana https://grafana.github.io/helm-charts
          helm repo add opentelemetry https://open-telemetry.github.io/opentelemetry-helm-charts
          helm dependency build ./helm/supersonic
          helm upgrade --install supersonic ./helm/supersonic \
            --values tests/values-external-envoy-config.yaml -n cms

      - name: Validate Envoy ConfigMap contains external config
        run: |
          echo "Checking that Envoy ConfigMap contains external configuration..."
          ENVOY_CONFIG=$(kubectl get configmap supersonic-envoy-config -n cms -o jsonpath="{.data.envoy\.yaml}")
          
          # Check for key indicators that external config was loaded
          if echo "$ENVOY_CONFIG" | grep -q "cms_local_rate_limiter"; then
            echo "✓ External config loaded: Found rate limiter configuration"
          else
            echo "✗ External config test failed: Rate limiter not found in config"
            exit 1
          fi
          
          if echo "$ENVOY_CONFIG" | grep -q "local_ratelimit"; then
            echo "✓ External config loaded: Found local rate limit filter"
          else
            echo "✗ External config test failed: Local rate limit filter not found"
            exit 1
          fi
          
          # Verify config doesn't contain dynamic generation markers
          if echo "$ENVOY_CONFIG" | grep -q ".Values.envoy"; then
            echo "✗ External config test failed: Dynamic template markers found in config"
            exit 1
          fi
          
          echo "✓ All external config validation checks passed"

      - name: CVMFS Mount ready
        run: |
          kubectl wait --for condition=Ready pod --all -n cvmfs-csi --timeout 120s

      - name: Envoy proxy ready
        run: |
          kubectl wait --for condition=Ready pod -l app.kubernetes.io/component=envoy --timeout 120s -n cms

      - name: Triton server ready
        run: |
          kubectl describe pod -l app.kubernetes.io/component=triton -n cms
          kubectl wait --for condition=Ready pod -l app.kubernetes.io/component=triton --timeout 500s -n cms

      - name: Validate Deployment
        run: |
          kubectl get all -n cms

      - name: Run Perf Analyzer Job
        run: |
          kubectl apply -f tests/perf-analyzer-job-ci.yaml
          kubectl wait --for=condition=complete job/perf-analyzer-job -n cms --timeout=300s || \
          (echo "Perf-analyzer job did not complete in time or failed." && exit 1)

          POD_NAME=$(kubectl get pods -n cms -l job-name=perf-analyzer-job -o jsonpath="{.items[0].metadata.name}")
          echo "========== Perf Analyzer Logs =========="
          kubectl logs -n cms "$POD_NAME" 
          echo "========================================"

      - name: Cleanup
        run: kind delete cluster --name gh-k8s-cluster
